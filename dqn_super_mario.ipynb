{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQNでマリオを動かしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import ppaquette_gym_super_mario\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapperの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env, skip=4):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    \n",
    "    def __init__(self, env, width=84, height=84, grayscale=True, dict_space_key=None):\n",
    "        \n",
    "        super().__init__(env)\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._grayscale = grayscale\n",
    "        self._key = dict_space_key\n",
    "        if self._grayscale:\n",
    "            num_colors = 1\n",
    "        else:\n",
    "            num_colors = 3\n",
    "\n",
    "        new_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self._height, self._width, num_colors),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "        if self._key is None:\n",
    "            original_space = self.observation_space\n",
    "            self.observation_space = new_space\n",
    "        else:\n",
    "            original_space = self.observation_space.spaces[self._key]\n",
    "            self.observation_space.spaces[self._key] = new_space\n",
    "        assert original_space.dtype == np.uint8 and len(original_space.shape) == 3\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \n",
    "        if self._key is None:\n",
    "            frame = obs\n",
    "        else:\n",
    "            frame = obs[self._key]\n",
    "\n",
    "        if self._grayscale:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(\n",
    "            frame, (self._width, self._height), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        if self._grayscale:\n",
    "            frame = np.expand_dims(frame, -1)\n",
    "\n",
    "        if self._key is None:\n",
    "            obs = frame\n",
    "        else:\n",
    "            obs = obs.copy()\n",
    "            obs[self._key] = frame\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        \n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \n",
    "        return np.sign(reward)\n",
    "\n",
    "\n",
    "class LazyFrames(object):\n",
    "    \n",
    "    def __init__(self, frames):\n",
    "        \n",
    "        self._frames = frames\n",
    "        self._out = None\n",
    "\n",
    "    def _force(self):\n",
    "        \n",
    "        if self._out is None:\n",
    "            self._out = np.concatenate(self._frames, axis=-1)\n",
    "            self._frames = None\n",
    "        return self._out\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        \n",
    "        out = self._force()\n",
    "        if dtype is not None:\n",
    "            out = out.astype(dtype)\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self._force())\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self._force()[i]\n",
    "\n",
    "    def count(self):\n",
    "        \n",
    "        frames = self._force()\n",
    "        return frames.shape[frames.ndim - 1]\n",
    "\n",
    "    def frame(self, i):\n",
    "        \n",
    "        return self._force()[..., i]\n",
    "    \n",
    "    \n",
    "class TorchFrame(gym.ObservationWrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        \n",
    "        super().__init__(env)\n",
    "        height, width, channels = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(channels, height, width),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \n",
    "        return torch.as_tensor(obs.transpose([2, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  環境生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action(command):\n",
    "    \n",
    "    if command == 0:\n",
    "        return [0, 0, 0, 1, 0, 0]\n",
    "    elif command == 1:\n",
    "        return [0, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def make_env(noop_max=30, skip=4, width=84, height=84, grayscale=True):\n",
    "    \n",
    "    env = gym.make('ppaquette/SuperMarioBros-1-1-v0')\n",
    "    env = MaxAndSkipEnv(env, skip=skip)\n",
    "    env = WarpFrame(env, width=width, height=height, grayscale=grayscale)\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = TorchFrame(env)\n",
    "    return env\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 78, Reward: 53.0\n",
      "Episode: 1, Step: 83, Reward: 52.0\n",
      "Episode: 2, Step: 122, Reward: 105.0\n",
      "Episode: 3, Step: 52, Reward: 52.0\n",
      "Episode: 4, Step: 92, Reward: 68.0\n"
     ]
    }
   ],
   "source": [
    "def random_agent():\n",
    "    \n",
    "    for episode_ in range(5):\n",
    "        obs_ = env.reset()\n",
    "        total_reward_ = 0\n",
    "\n",
    "        step_ = 0\n",
    "        while True:\n",
    "            action_ = make_action(np.random.randint(0, 2))\n",
    "            obs_, reward_, done_, info_ = env.step(action_)\n",
    "            total_reward_ += reward_\n",
    "            if done_ or info_[\"time\"] <= 200:\n",
    "                break\n",
    "\n",
    "            step_ += 1\n",
    "\n",
    "        print(f\"Episode: {episode_}, Step: {step_}, Reward: {total_reward_}\")\n",
    "\n",
    "#random_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リプレイバッファ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, buffer_size):\n",
    "        \n",
    "        self.buffer_size = buffer_size\n",
    "        self.index = 0\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros(buffer_size, dtype=np.float32)\n",
    "        self.priorities[0] = 1.0\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.buffer)\n",
    "\n",
    "    # 経験をリプレイバッファに保存する． 経験は(obs, action, reward, next_obs, done)の5つ組を想定    \n",
    "    def push(self, experience):\n",
    "        \n",
    "        if len(self.buffer) < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "        else:\n",
    "            self.buffer[self.index] = experience\n",
    "\n",
    "        # 優先度は最初は大きな値で初期化しておき, 後でサンプルされた時に更新する\n",
    "        self.priorities[self.index] = self.priorities.max()\n",
    "        self.index = (self.index + 1) % self.buffer_size\n",
    "    \n",
    "    def sample(self, batch_size, alpha=0.6, beta=0.4):\n",
    "        \n",
    "        # 現在経験が入っている部分に対応する優先度を取り出し, サンプルする確率を計算\n",
    "        priorities = self.priorities[: self.buffer_size if len(self.buffer) == self.buffer_size else self.index]\n",
    "        priorities = priorities ** alpha\n",
    "        prob = priorities / priorities.sum()\n",
    "\n",
    "        # 上で計算した確率に従ってリプレイバッファ中のインデックスをサンプルする\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=prob)\n",
    "\n",
    "        # 学習の方向性を補正するための重みを計算\n",
    "        weights = (len(self.buffer) * prob[indices]) ** (-beta)\n",
    "        weights = weights / weights.max()\n",
    "\n",
    "        # 上でサンプルしたインデックスに基づいて経験をサンプルし, (obs, action, reward, next_obs, done)に分ける\n",
    "        obs, action, reward, next_obs, done = zip(*[self.buffer[i] for i in indices])\n",
    "\n",
    "        # あとで計算しやすいようにtorch.Tensorに変換して(obs, action, reward, next_obs, done, indices, weights)の7つ組を返す\n",
    "        return (torch.stack(obs),\n",
    "                torch.as_tensor(action), \n",
    "                torch.as_tensor(reward, dtype=torch.float32),\n",
    "                torch.stack(next_obs), \n",
    "                torch.as_tensor(done, dtype=torch.uint8),\n",
    "                indices,\n",
    "                torch.as_tensor(weights, dtype=torch.float32))\n",
    "\n",
    "    # 優先度を更新する. 優先度が極端に小さくなって経験が全く選ばれないということがないように, 微小値を加算しておく.\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \n",
    "        self.priorities[indices] = priorities + 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNQNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_shape, n_action):\n",
    "        \n",
    "        super(CNNQNetwork, self).__init__()\n",
    "        self.state_shape = state_shape\n",
    "        self.n_action = n_action\n",
    "        # Dueling Networkでも, 畳込み部分は共有する\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(state_shape[0], 32, kernel_size=8, stride=4),  # 1x84x84 -> 32x20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),  # 32x20x20 -> 64x9x9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),  # 64x9x9 -> 64x7x7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Dueling Networkのための分岐した全結合層\n",
    "        # 状態価値\n",
    "        self.fc_state = nn.Sequential(\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "        # アドバンテージ\n",
    "        self.fc_advantage = nn.Sequential(\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_action)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        \n",
    "        feature = self.conv_layers(obs)\n",
    "        feature = feature.view(feature.size(0), -1)  #　Flatten. 64x7x7　-> 3136\n",
    "\n",
    "        state_values = self.fc_state(feature)\n",
    "        advantage = self.fc_advantage(feature)\n",
    "\n",
    "        # 状態価値 + アドバンテージ で行動価値を計算しますが、安定化のためアドバンテージの（行動間での）平均を引きます\n",
    "        action_values = state_values + advantage - torch.mean(advantage, dim=1, keepdim=True)\n",
    "        return action_values\n",
    "\n",
    "    # epsilon-greedy. 確率epsilonでランダムに行動し, それ以外はニューラルネットワークの予測結果に基づいてgreedyに行動します. \n",
    "    def act(self, obs, epsilon):\n",
    "        \n",
    "        if random.random() < epsilon:\n",
    "            action = random.randrange(self.n_action)\n",
    "        else:\n",
    "            # 行動を選択する時には勾配を追跡する必要がない\n",
    "            with torch.no_grad():\n",
    "                action = torch.argmax(self.forward(obs.unsqueeze(0))).item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 100000  #　リプレイバッファに入る経験の最大数\n",
    "initial_buffer_size = 1000  # 学習を開始する最低限の経験の数\n",
    "replay_buffer = PrioritizedReplayBuffer(buffer_size)\n",
    "\n",
    "net = CNNQNetwork(env.observation_space.shape, n_action=2).to(device)\n",
    "target_net = CNNQNetwork(env.observation_space.shape, n_action=2).to(device)\n",
    "target_update_interval = 200  # 学習安定化のために用いるターゲットネットワークの同期間隔\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)  # オプティマイザはAdam\n",
    "loss_func = nn.SmoothL1Loss(reduction='none')  # ロスはSmoothL1loss（別名Huber loss）\n",
    "\n",
    "beta_begin = 0.4\n",
    "beta_end = 1.0\n",
    "beta_decay = 500000\n",
    "# beta_beginから始めてbeta_endまでbeta_decayかけて線形に増やす\n",
    "beta_func = lambda step: min(beta_end, beta_begin + (beta_end - beta_begin) * (step / beta_decay))\n",
    "\n",
    "epsilon_begin = 1.0\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 50000\n",
    "# epsilon_beginから始めてepsilon_endまでepsilon_decayかけて線形に減らす\n",
    "epsilon_func = lambda step: max(epsilon_end, epsilon_begin - (epsilon_begin - epsilon_end) * (step / epsilon_decay))\n",
    "\n",
    "gamma = 0.99  #　割引率\n",
    "batch_size = 32\n",
    "n_episodes = 500  # 学習を行うエピソード数\n",
    "time_limit = 200  # エピソードを打ち切るしきい値\n",
    "model_path = \"models\"  # モデルの保存先"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(batch_size, beta):\n",
    "    \n",
    "    obs, action, reward, next_obs, done, indices, weights = replay_buffer.sample(batch_size, beta)\n",
    "    obs, action, reward, next_obs, done, weights \\\n",
    "        = obs.float().to(device), action.to(device), reward.to(device), next_obs.float().to(device), done.to(device), weights.to(device)\n",
    "\n",
    "    #　ニューラルネットワークによるQ関数の出力から, .gatherで実際に選択した行動に対応する価値を集めてきます.\n",
    "    q_values = net(obs).gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    \n",
    "    # 目標値の計算なので勾配を追跡しない\n",
    "    with torch.no_grad():\n",
    "        # Double DQN. \n",
    "        # ① 現在のQ関数でgreedyに行動を選択し, \n",
    "        greedy_action_next = torch.argmax(net(next_obs), dim=1)\n",
    "        # ②　対応する価値はターゲットネットワークのものを参照します.\n",
    "        q_values_next = target_net(next_obs).gather(1, greedy_action_next.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    # ベルマン方程式に基づき, 更新先の価値を計算します.\n",
    "    # (1 - done)をかけているのは, ゲームが終わった後の価値は0とみなすためです.\n",
    "    target_q_values = reward + gamma * q_values_next * (1 - done)\n",
    "\n",
    "    # Prioritized Experience Replayのために, ロスに重み付けを行なって更新します.\n",
    "    optimizer.zero_grad()\n",
    "    loss = (weights * loss_func(q_values, target_q_values)).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #　TD誤差に基づいて, サンプルされた経験の優先度を更新します.\n",
    "    replay_buffer.update_priorities(indices, (target_q_values - q_values).abs().detach().cpu().numpy())\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習スクリプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1501, Step: 251931, Reward: 255.0\n",
      "Episode: 1502, Step: 252060, Reward: 129.0\n",
      "Episode: 1503, Step: 252180, Reward: 120.0\n",
      "Episode: 1504, Step: 252300, Reward: 120.0\n",
      "Episode: 1505, Step: 252521, Reward: 210.0\n",
      "Episode: 1506, Step: 253019, Reward: 228.0\n",
      "Episode: 1507, Step: 253516, Reward: 163.0\n",
      "Episode: 1508, Step: 253678, Reward: 158.0\n",
      "Episode: 1509, Step: 254162, Reward: 230.0\n",
      "Episode: 1510, Step: 254642, Reward: 253.0\n",
      "Episode: 1511, Step: 254754, Reward: 112.0\n",
      "Episode: 1512, Step: 255225, Reward: 164.0\n",
      "Episode: 1513, Step: 255336, Reward: 111.0\n",
      "Episode: 1514, Step: 255633, Reward: 255.0\n",
      "Episode: 1515, Step: 256122, Reward: 181.0\n",
      "Episode: 1516, Step: 256251, Reward: 129.0\n",
      "Episode: 1517, Step: 256731, Reward: 248.0\n",
      "Episode: 1518, Step: 257231, Reward: 183.0\n",
      "Episode: 1519, Step: 257702, Reward: 238.0\n",
      "Episode: 1520, Step: 257917, Reward: 213.0\n",
      "Episode: 1521, Step: 258058, Reward: 141.0\n",
      "Episode: 1522, Step: 258547, Reward: 228.0\n",
      "Episode: 1523, Step: 258762, Reward: 188.0\n",
      "Episode: 1524, Step: 258814, Reward: 52.0\n",
      "Episode: 1525, Step: 259314, Reward: 228.0\n",
      "Episode: 1526, Step: 259525, Reward: 208.0\n",
      "Episode: 1527, Step: 259607, Reward: 54.0\n",
      "Episode: 1528, Step: 259718, Reward: 111.0\n",
      "Episode: 1529, Step: 259863, Reward: 145.0\n",
      "Episode: 1530, Step: 259956, Reward: 93.0\n",
      "Episode: 1531, Step: 260436, Reward: 226.0\n",
      "Episode: 1532, Step: 260777, Reward: 185.0\n",
      "Episode: 1533, Step: 261248, Reward: 223.0\n",
      "Episode: 1534, Step: 261531, Reward: 260.0\n",
      "Episode: 1535, Step: 261613, Reward: 54.0\n",
      "Episode: 1536, Step: 261762, Reward: 146.0\n",
      "Episode: 1537, Step: 261783, Reward: 21.0\n",
      "Episode: 1538, Step: 262275, Reward: 262.0\n",
      "Episode: 1539, Step: 262775, Reward: 163.0\n",
      "Episode: 1540, Step: 263092, Reward: 264.0\n",
      "Episode: 1541, Step: 263239, Reward: 147.0\n",
      "Episode: 1542, Step: 263520, Reward: 257.0\n",
      "Episode: 1543, Step: 263792, Reward: 258.0\n",
      "Episode: 1544, Step: 264019, Reward: 206.0\n",
      "Episode: 1545, Step: 264181, Reward: 160.0\n",
      "Episode: 1546, Step: 264577, Reward: 217.0\n",
      "Episode: 1547, Step: 264708, Reward: 131.0\n",
      "Episode: 1548, Step: 265206, Reward: 244.0\n",
      "Episode: 1549, Step: 265289, Reward: 69.0\n",
      "Episode: 1550, Step: 265576, Reward: 264.0\n",
      "Episode: 1551, Step: 265698, Reward: 122.0\n",
      "Episode: 1552, Step: 266028, Reward: 189.0\n",
      "Episode: 1553, Step: 266302, Reward: 259.0\n",
      "Episode: 1554, Step: 266458, Reward: 155.0\n",
      "Episode: 1555, Step: 266869, Reward: 263.0\n",
      "Episode: 1556, Step: 267254, Reward: 255.0\n",
      "Episode: 1557, Step: 267410, Reward: 156.0\n",
      "Episode: 1558, Step: 267773, Reward: 255.0\n",
      "Episode: 1559, Step: 268068, Reward: 208.0\n",
      "Episode: 1560, Step: 268444, Reward: 266.0\n",
      "Episode: 1561, Step: 268886, Reward: 251.0\n",
      "Episode: 1562, Step: 269040, Reward: 153.0\n",
      "Episode: 1563, Step: 269314, Reward: 258.0\n",
      "Episode: 1564, Step: 269611, Reward: 257.0\n",
      "Episode: 1565, Step: 270020, Reward: 263.0\n",
      "Episode: 1566, Step: 270500, Reward: 168.0\n",
      "Episode: 1567, Step: 270841, Reward: 261.0\n",
      "Episode: 1568, Step: 271025, Reward: 158.0\n",
      "Episode: 1569, Step: 271161, Reward: 135.0\n",
      "Episode: 1570, Step: 271658, Reward: 223.0\n",
      "Episode: 1571, Step: 271816, Reward: 157.0\n",
      "Episode: 1572, Step: 272300, Reward: 229.0\n",
      "Episode: 1573, Step: 272780, Reward: 227.0\n",
      "Episode: 1574, Step: 273162, Reward: 256.0\n",
      "Episode: 1575, Step: 273315, Reward: 152.0\n",
      "Episode: 1576, Step: 273617, Reward: 256.0\n",
      "Episode: 1577, Step: 273933, Reward: 252.0\n",
      "Episode: 1578, Step: 274087, Reward: 153.0\n",
      "Episode: 1579, Step: 274571, Reward: 255.0\n",
      "Episode: 1580, Step: 274730, Reward: 157.0\n",
      "Episode: 1581, Step: 275202, Reward: 260.0\n",
      "Episode: 1582, Step: 275673, Reward: 172.0\n",
      "Episode: 1583, Step: 275695, Reward: 22.0\n",
      "Episode: 1584, Step: 275809, Reward: 113.0\n",
      "Episode: 1585, Step: 275918, Reward: 108.0\n",
      "Episode: 1586, Step: 276194, Reward: 263.0\n",
      "Episode: 1587, Step: 276518, Reward: 259.0\n",
      "Episode: 1588, Step: 276667, Reward: 148.0\n",
      "Episode: 1589, Step: 277122, Reward: 261.0\n",
      "Episode: 1590, Step: 277276, Reward: 153.0\n",
      "Episode: 1591, Step: 277689, Reward: 256.0\n",
      "Episode: 1592, Step: 277841, Reward: 151.0\n",
      "Episode: 1593, Step: 278340, Reward: 250.0\n",
      "Episode: 1594, Step: 278616, Reward: 261.0\n",
      "Episode: 1595, Step: 278766, Reward: 149.0\n",
      "Episode: 1596, Step: 279040, Reward: 258.0\n",
      "Episode: 1597, Step: 279191, Reward: 150.0\n",
      "Episode: 1598, Step: 279461, Reward: 258.0\n",
      "Episode: 1599, Step: 279950, Reward: 220.0\n",
      "Episode: 1600, Step: 280095, Reward: 144.0\n",
      "Episode: 1601, Step: 280202, Reward: 106.0\n",
      "Episode: 1602, Step: 280348, Reward: 146.0\n",
      "Episode: 1603, Step: 280504, Reward: 155.0\n",
      "Episode: 1604, Step: 281002, Reward: 182.0\n",
      "Episode: 1605, Step: 281402, Reward: 259.0\n",
      "Episode: 1606, Step: 281739, Reward: 188.0\n",
      "Episode: 1607, Step: 281891, Reward: 151.0\n",
      "Episode: 1608, Step: 282015, Reward: 123.0\n",
      "Episode: 1609, Step: 282289, Reward: 260.0\n",
      "Episode: 1610, Step: 282397, Reward: 107.0\n",
      "Episode: 1611, Step: 282550, Reward: 152.0\n",
      "Episode: 1612, Step: 283047, Reward: 235.0\n",
      "Episode: 1613, Step: 283536, Reward: 208.0\n",
      "Episode: 1614, Step: 283876, Reward: 259.0\n",
      "Episode: 1615, Step: 284012, Reward: 136.0\n",
      "Episode: 1616, Step: 284104, Reward: 92.0\n",
      "Episode: 1617, Step: 284390, Reward: 259.0\n",
      "Episode: 1618, Step: 284662, Reward: 251.0\n",
      "Episode: 1619, Step: 284814, Reward: 151.0\n",
      "Episode: 1620, Step: 285213, Reward: 259.0\n",
      "Episode: 1621, Step: 285697, Reward: 190.0\n",
      "Episode: 1622, Step: 285897, Reward: 195.0\n",
      "Episode: 1623, Step: 286208, Reward: 258.0\n",
      "Episode: 1624, Step: 286505, Reward: 260.0\n",
      "Episode: 1625, Step: 286762, Reward: 247.0\n",
      "Episode: 1626, Step: 286875, Reward: 113.0\n",
      "Episode: 1627, Step: 287215, Reward: 264.0\n",
      "Episode: 1628, Step: 287483, Reward: 258.0\n",
      "Episode: 1629, Step: 287575, Reward: 92.0\n",
      "Episode: 1630, Step: 288087, Reward: 265.0\n",
      "Episode: 1631, Step: 288558, Reward: 184.0\n",
      "Episode: 1632, Step: 288900, Reward: 261.0\n",
      "Episode: 1633, Step: 289306, Reward: 260.0\n",
      "Episode: 1634, Step: 289525, Reward: 210.0\n",
      "Episode: 1635, Step: 289795, Reward: 258.0\n",
      "Episode: 1636, Step: 290275, Reward: 242.0\n",
      "Episode: 1637, Step: 290775, Reward: 177.0\n",
      "Episode: 1638, Step: 291228, Reward: 258.0\n",
      "Episode: 1639, Step: 291670, Reward: 259.0\n",
      "Episode: 1640, Step: 291824, Reward: 153.0\n",
      "Episode: 1641, Step: 292301, Reward: 261.0\n",
      "Episode: 1642, Step: 292457, Reward: 155.0\n",
      "Episode: 1643, Step: 292772, Reward: 252.0\n",
      "Episode: 1644, Step: 293098, Reward: 189.0\n",
      "Episode: 1645, Step: 293427, Reward: 258.0\n",
      "Episode: 1646, Step: 293696, Reward: 256.0\n",
      "Episode: 1647, Step: 293850, Reward: 153.0\n",
      "Episode: 1648, Step: 294271, Reward: 259.0\n",
      "Episode: 1649, Step: 294425, Reward: 153.0\n",
      "Episode: 1650, Step: 294885, Reward: 257.0\n",
      "Episode: 1651, Step: 295367, Reward: 262.0\n",
      "Episode: 1652, Step: 295838, Reward: 229.0\n",
      "Episode: 1653, Step: 295988, Reward: 150.0\n",
      "Episode: 1654, Step: 296253, Reward: 253.0\n",
      "Episode: 1655, Step: 296403, Reward: 150.0\n",
      "Episode: 1656, Step: 296733, Reward: 262.0\n",
      "Episode: 1657, Step: 297213, Reward: 226.0\n",
      "Episode: 1658, Step: 297713, Reward: 165.0\n",
      "Episode: 1659, Step: 298034, Reward: 258.0\n",
      "Episode: 1660, Step: 298532, Reward: 236.0\n",
      "Episode: 1661, Step: 298850, Reward: 256.0\n",
      "Episode: 1662, Step: 298942, Reward: 92.0\n",
      "Episode: 1663, Step: 299345, Reward: 198.0\n",
      "Episode: 1664, Step: 299472, Reward: 126.0\n",
      "Episode: 1665, Step: 299595, Reward: 123.0\n",
      "Episode: 1666, Step: 299687, Reward: 92.0\n",
      "Episode: 1667, Step: 300185, Reward: 209.0\n",
      "Episode: 1668, Step: 300308, Reward: 123.0\n",
      "Episode: 1669, Step: 300761, Reward: 195.0\n",
      "Episode: 1670, Step: 301225, Reward: 260.0\n",
      "Episode: 1671, Step: 301317, Reward: 92.0\n",
      "Episode: 1672, Step: 301588, Reward: 258.0\n",
      "Episode: 1673, Step: 301785, Reward: 189.0\n",
      "Episode: 1674, Step: 301937, Reward: 151.0\n",
      "Episode: 1675, Step: 302089, Reward: 151.0\n",
      "Episode: 1676, Step: 302387, Reward: 213.0\n",
      "Episode: 1677, Step: 302838, Reward: 255.0\n",
      "Episode: 1678, Step: 303122, Reward: 257.0\n",
      "Episode: 1679, Step: 303499, Reward: 263.0\n",
      "Episode: 1680, Step: 303701, Reward: 193.0\n",
      "Episode: 1681, Step: 303996, Reward: 260.0\n",
      "Episode: 1682, Step: 304493, Reward: 225.0\n",
      "Episode: 1683, Step: 304644, Reward: 150.0\n",
      "Episode: 1684, Step: 305128, Reward: 224.0\n",
      "Episode: 1685, Step: 305439, Reward: 253.0\n",
      "Episode: 1686, Step: 305568, Reward: 127.0\n",
      "Episode: 1687, Step: 306039, Reward: 188.0\n",
      "Episode: 1688, Step: 306093, Reward: 54.0\n",
      "Episode: 1689, Step: 306590, Reward: 221.0\n",
      "Episode: 1690, Step: 306795, Reward: 197.0\n",
      "Episode: 1691, Step: 306946, Reward: 150.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1692, Step: 307102, Reward: 155.0\n",
      "Episode: 1693, Step: 307602, Reward: 245.0\n",
      "Episode: 1694, Step: 308073, Reward: 245.0\n",
      "Episode: 1695, Step: 308571, Reward: 172.0\n",
      "Episode: 1696, Step: 308871, Reward: 256.0\n",
      "Episode: 1697, Step: 308958, Reward: 87.0\n",
      "Episode: 1698, Step: 309270, Reward: 261.0\n",
      "Episode: 1699, Step: 309750, Reward: 231.0\n",
      "Episode: 1700, Step: 309884, Reward: 134.0\n",
      "Episode: 1701, Step: 310034, Reward: 150.0\n",
      "Episode: 1702, Step: 310168, Reward: 134.0\n",
      "Episode: 1703, Step: 310665, Reward: 235.0\n",
      "Episode: 1704, Step: 311026, Reward: 259.0\n",
      "Episode: 1705, Step: 311163, Reward: 136.0\n",
      "Episode: 1706, Step: 311643, Reward: 233.0\n",
      "Episode: 1707, Step: 312102, Reward: 261.0\n",
      "Episode: 1708, Step: 312411, Reward: 254.0\n",
      "Episode: 1709, Step: 312710, Reward: 262.0\n",
      "Episode: 1710, Step: 312909, Reward: 195.0\n",
      "Episode: 1711, Step: 313187, Reward: 257.0\n",
      "Episode: 1712, Step: 313614, Reward: 262.0\n",
      "Episode: 1713, Step: 313782, Reward: 143.0\n",
      "Episode: 1714, Step: 314282, Reward: 215.0\n",
      "Episode: 1715, Step: 314585, Reward: 189.0\n",
      "Episode: 1716, Step: 315083, Reward: 249.0\n",
      "Episode: 1717, Step: 315580, Reward: 227.0\n",
      "Episode: 1718, Step: 316069, Reward: 216.0\n",
      "Episode: 1719, Step: 316553, Reward: 177.0\n",
      "Episode: 1720, Step: 316939, Reward: 261.0\n",
      "Episode: 1721, Step: 317311, Reward: 272.0\n",
      "Episode: 1722, Step: 317641, Reward: 264.0\n",
      "Episode: 1723, Step: 318139, Reward: 258.0\n",
      "Episode: 1724, Step: 318427, Reward: 262.0\n",
      "Episode: 1725, Step: 318621, Reward: 191.0\n",
      "Episode: 1726, Step: 318962, Reward: 250.0\n",
      "Episode: 1727, Step: 319286, Reward: 246.0\n",
      "Episode: 1728, Step: 319553, Reward: 255.0\n",
      "Episode: 1729, Step: 319854, Reward: 197.0\n",
      "Episode: 1730, Step: 320352, Reward: 226.0\n",
      "Episode: 1731, Step: 320506, Reward: 153.0\n",
      "Episode: 1732, Step: 320767, Reward: 251.0\n",
      "Episode: 1733, Step: 320881, Reward: 114.0\n",
      "Episode: 1734, Step: 321205, Reward: 255.0\n",
      "Episode: 1735, Step: 321705, Reward: 166.0\n",
      "Episode: 1736, Step: 322176, Reward: 181.0\n",
      "Episode: 1737, Step: 322451, Reward: 257.0\n",
      "Episode: 1738, Step: 322726, Reward: 260.0\n",
      "Episode: 1739, Step: 323215, Reward: 226.0\n",
      "Episode: 1740, Step: 323237, Reward: 22.0\n",
      "Episode: 1741, Step: 323510, Reward: 259.0\n",
      "Episode: 1742, Step: 323928, Reward: 263.0\n",
      "Episode: 1743, Step: 324204, Reward: 259.0\n",
      "Episode: 1744, Step: 324551, Reward: 258.0\n",
      "Episode: 1745, Step: 325048, Reward: 224.0\n",
      "Episode: 1746, Step: 325258, Reward: 193.0\n",
      "Episode: 1747, Step: 325742, Reward: 251.0\n",
      "Episode: 1748, Step: 326222, Reward: 249.0\n",
      "Episode: 1749, Step: 326634, Reward: 270.0\n",
      "Episode: 1750, Step: 326720, Reward: 86.0\n",
      "Episode: 1751, Step: 326995, Reward: 262.0\n",
      "Episode: 1752, Step: 327148, Reward: 153.0\n",
      "Episode: 1753, Step: 327447, Reward: 262.0\n",
      "Episode: 1754, Step: 327931, Reward: 228.0\n",
      "Episode: 1755, Step: 328411, Reward: 172.0\n",
      "Episode: 1756, Step: 328696, Reward: 256.0\n",
      "Episode: 1757, Step: 328919, Reward: 192.0\n",
      "Episode: 1758, Step: 329212, Reward: 253.0\n",
      "Episode: 1759, Step: 329650, Reward: 265.0\n",
      "Episode: 1760, Step: 330139, Reward: 231.0\n",
      "Episode: 1761, Step: 330623, Reward: 163.0\n",
      "Episode: 1762, Step: 331103, Reward: 249.0\n",
      "Episode: 1763, Step: 331384, Reward: 261.0\n",
      "Episode: 1764, Step: 331855, Reward: 258.0\n",
      "Episode: 1765, Step: 331910, Reward: 55.0\n",
      "Episode: 1766, Step: 332234, Reward: 250.0\n",
      "Episode: 1767, Step: 332518, Reward: 262.0\n",
      "Episode: 1768, Step: 332668, Reward: 149.0\n",
      "Episode: 1769, Step: 332942, Reward: 253.0\n",
      "Episode: 1770, Step: 333242, Reward: 266.0\n",
      "Episode: 1771, Step: 333713, Reward: 187.0\n",
      "Episode: 1772, Step: 333998, Reward: 258.0\n",
      "Episode: 1773, Step: 334495, Reward: 252.0\n",
      "Episode: 1774, Step: 334802, Reward: 259.0\n",
      "Episode: 1775, Step: 335223, Reward: 255.0\n",
      "Episode: 1776, Step: 335499, Reward: 260.0\n",
      "Episode: 1777, Step: 335999, Reward: 227.0\n",
      "Episode: 1778, Step: 336281, Reward: 263.0\n",
      "Episode: 1779, Step: 336714, Reward: 266.0\n",
      "Episode: 1780, Step: 337211, Reward: 168.0\n",
      "Episode: 1781, Step: 337646, Reward: 260.0\n",
      "Episode: 1782, Step: 338146, Reward: 267.0\n",
      "Episode: 1783, Step: 338425, Reward: 251.0\n",
      "Episode: 1784, Step: 338781, Reward: 262.0\n",
      "Episode: 1785, Step: 339057, Reward: 262.0\n",
      "Episode: 1786, Step: 339365, Reward: 259.0\n",
      "Episode: 1787, Step: 339566, Reward: 195.0\n",
      "Episode: 1788, Step: 340055, Reward: 231.0\n",
      "Episode: 1789, Step: 340336, Reward: 192.0\n",
      "Episode: 1790, Step: 340815, Reward: 265.0\n",
      "Episode: 1791, Step: 341014, Reward: 196.0\n",
      "Episode: 1792, Step: 341282, Reward: 192.0\n",
      "Episode: 1793, Step: 341780, Reward: 234.0\n",
      "Episode: 1794, Step: 341920, Reward: 137.0\n",
      "Episode: 1795, Step: 342071, Reward: 150.0\n",
      "Episode: 1796, Step: 342292, Reward: 218.0\n",
      "Episode: 1797, Step: 342509, Reward: 217.0\n",
      "Episode: 1798, Step: 342663, Reward: 153.0\n",
      "Episode: 1799, Step: 342941, Reward: 264.0\n",
      "Episode: 1800, Step: 343138, Reward: 194.0\n",
      "Episode: 1801, Step: 343592, Reward: 262.0\n",
      "Episode: 1802, Step: 343863, Reward: 260.0\n",
      "Episode: 1803, Step: 344246, Reward: 259.0\n",
      "Episode: 1804, Step: 344726, Reward: 252.0\n",
      "Episode: 1805, Step: 344879, Reward: 153.0\n",
      "Episode: 1806, Step: 345350, Reward: 169.0\n",
      "Episode: 1807, Step: 345620, Reward: 259.0\n",
      "Episode: 1808, Step: 345777, Reward: 155.0\n",
      "Episode: 1809, Step: 345926, Reward: 144.0\n",
      "Episode: 1810, Step: 346192, Reward: 255.0\n",
      "Episode: 1811, Step: 346464, Reward: 255.0\n",
      "Episode: 1812, Step: 346551, Reward: 87.0\n",
      "Episode: 1813, Step: 346821, Reward: 254.0\n",
      "Episode: 1814, Step: 347319, Reward: 238.0\n",
      "Episode: 1815, Step: 347816, Reward: 252.0\n",
      "Episode: 1816, Step: 348036, Reward: 215.0\n",
      "Episode: 1817, Step: 348479, Reward: 198.0\n",
      "Episode: 1818, Step: 348959, Reward: 239.0\n",
      "Episode: 1819, Step: 349043, Reward: 56.0\n",
      "Episode: 1820, Step: 349311, Reward: 252.0\n",
      "Episode: 1821, Step: 349446, Reward: 135.0\n",
      "Episode: 1822, Step: 349799, Reward: 258.0\n",
      "Episode: 1823, Step: 349996, Reward: 192.0\n",
      "Episode: 1824, Step: 350386, Reward: 262.0\n",
      "Episode: 1825, Step: 350538, Reward: 151.0\n",
      "Episode: 1826, Step: 350771, Reward: 150.0\n",
      "Episode: 1827, Step: 351242, Reward: 165.0\n",
      "Episode: 1828, Step: 351377, Reward: 135.0\n",
      "Episode: 1829, Step: 351484, Reward: 106.0\n",
      "Episode: 1830, Step: 351638, Reward: 153.0\n",
      "Episode: 1831, Step: 351833, Reward: 194.0\n",
      "Episode: 1832, Step: 352274, Reward: 258.0\n",
      "Episode: 1833, Step: 352774, Reward: 228.0\n",
      "Episode: 1834, Step: 353106, Reward: 254.0\n",
      "Episode: 1835, Step: 353443, Reward: 258.0\n",
      "Episode: 1836, Step: 353907, Reward: 255.0\n",
      "Episode: 1837, Step: 354050, Reward: 138.0\n",
      "Episode: 1838, Step: 354534, Reward: 227.0\n",
      "Episode: 1839, Step: 354804, Reward: 258.0\n",
      "Episode: 1840, Step: 355304, Reward: 178.0\n",
      "Episode: 1841, Step: 355775, Reward: 174.0\n",
      "Episode: 1842, Step: 355910, Reward: 135.0\n",
      "Episode: 1843, Step: 356156, Reward: 198.0\n",
      "Episode: 1844, Step: 356492, Reward: 255.0\n",
      "Episode: 1845, Step: 356743, Reward: 188.0\n",
      "Episode: 1846, Step: 356878, Reward: 135.0\n",
      "Episode: 1847, Step: 357378, Reward: 231.0\n",
      "Episode: 1848, Step: 357819, Reward: 262.0\n",
      "Episode: 1849, Step: 357954, Reward: 135.0\n",
      "Episode: 1850, Step: 358238, Reward: 264.0\n",
      "Episode: 1851, Step: 358727, Reward: 166.0\n",
      "Episode: 1852, Step: 358929, Reward: 196.0\n",
      "Episode: 1853, Step: 359409, Reward: 235.0\n",
      "Episode: 1854, Step: 359677, Reward: 254.0\n",
      "Episode: 1855, Step: 360123, Reward: 255.0\n",
      "Episode: 1856, Step: 360394, Reward: 259.0\n",
      "Episode: 1857, Step: 360817, Reward: 261.0\n",
      "Episode: 1858, Step: 361306, Reward: 181.0\n",
      "Episode: 1859, Step: 361502, Reward: 193.0\n",
      "Episode: 1860, Step: 361774, Reward: 254.0\n",
      "Episode: 1861, Step: 362059, Reward: 196.0\n",
      "Episode: 1862, Step: 362530, Reward: 234.0\n",
      "Episode: 1863, Step: 362967, Reward: 252.0\n",
      "Episode: 1864, Step: 363193, Reward: 189.0\n",
      "Episode: 1865, Step: 363553, Reward: 258.0\n",
      "Episode: 1866, Step: 364037, Reward: 206.0\n",
      "Episode: 1867, Step: 364481, Reward: 261.0\n",
      "Episode: 1868, Step: 364941, Reward: 266.0\n",
      "Episode: 1869, Step: 365053, Reward: 112.0\n",
      "Episode: 1870, Step: 365553, Reward: 256.0\n",
      "Episode: 1871, Step: 366028, Reward: 260.0\n",
      "Episode: 1872, Step: 366517, Reward: 235.0\n",
      "Episode: 1873, Step: 366787, Reward: 258.0\n",
      "Episode: 1874, Step: 367156, Reward: 257.0\n",
      "Episode: 1875, Step: 367656, Reward: 163.0\n",
      "Episode: 1876, Step: 367928, Reward: 260.0\n",
      "Episode: 1877, Step: 368426, Reward: 187.0\n",
      "Episode: 1878, Step: 368923, Reward: 235.0\n",
      "Episode: 1879, Step: 369253, Reward: 258.0\n",
      "Episode: 1880, Step: 369466, Reward: 213.0\n",
      "Episode: 1881, Step: 369618, Reward: 152.0\n",
      "Episode: 1882, Step: 370118, Reward: 214.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1883, Step: 370460, Reward: 254.0\n",
      "Episode: 1884, Step: 370895, Reward: 257.0\n",
      "Episode: 1885, Step: 371047, Reward: 151.0\n",
      "Episode: 1886, Step: 371199, Reward: 152.0\n",
      "Episode: 1887, Step: 371305, Reward: 106.0\n",
      "Episode: 1888, Step: 371785, Reward: 186.0\n",
      "Episode: 1889, Step: 372285, Reward: 230.0\n",
      "Episode: 1890, Step: 372613, Reward: 254.0\n",
      "Episode: 1891, Step: 372919, Reward: 251.0\n",
      "Episode: 1892, Step: 373137, Reward: 213.0\n",
      "Episode: 1893, Step: 373289, Reward: 152.0\n",
      "Episode: 1894, Step: 373628, Reward: 258.0\n",
      "Episode: 1895, Step: 374081, Reward: 262.0\n",
      "Episode: 1896, Step: 374581, Reward: 181.0\n",
      "Episode: 1897, Step: 375052, Reward: 237.0\n",
      "Episode: 1898, Step: 375162, Reward: 110.0\n",
      "Episode: 1899, Step: 375431, Reward: 254.0\n",
      "Episode: 1900, Step: 375743, Reward: 264.0\n",
      "Episode: 1901, Step: 376227, Reward: 240.0\n",
      "Episode: 1902, Step: 376598, Reward: 263.0\n",
      "Episode: 1903, Step: 377105, Reward: 258.0\n",
      "Episode: 1904, Step: 377524, Reward: 258.0\n",
      "Episode: 1905, Step: 377926, Reward: 261.0\n",
      "Episode: 1906, Step: 378438, Reward: 253.0\n",
      "Episode: 1907, Step: 378707, Reward: 256.0\n",
      "Episode: 1908, Step: 379081, Reward: 260.0\n",
      "Episode: 1909, Step: 379365, Reward: 262.0\n",
      "Episode: 1910, Step: 379865, Reward: 236.0\n",
      "Episode: 1911, Step: 379919, Reward: 54.0\n",
      "Episode: 1912, Step: 380064, Reward: 145.0\n",
      "Episode: 1913, Step: 380561, Reward: 181.0\n",
      "Episode: 1914, Step: 380976, Reward: 251.0\n",
      "Episode: 1915, Step: 381362, Reward: 257.0\n",
      "Episode: 1916, Step: 381496, Reward: 134.0\n",
      "Episode: 1917, Step: 381996, Reward: 228.0\n",
      "Episode: 1918, Step: 382467, Reward: 252.0\n",
      "Episode: 1919, Step: 382621, Reward: 153.0\n",
      "Episode: 1920, Step: 382927, Reward: 253.0\n",
      "Episode: 1921, Step: 383058, Reward: 131.0\n",
      "Episode: 1922, Step: 383490, Reward: 262.0\n",
      "Episode: 1923, Step: 383713, Reward: 220.0\n",
      "Episode: 1924, Step: 384182, Reward: 260.0\n",
      "Episode: 1925, Step: 384653, Reward: 234.0\n",
      "Episode: 1926, Step: 385083, Reward: 260.0\n",
      "Episode: 1927, Step: 385580, Reward: 243.0\n",
      "Episode: 1928, Step: 385854, Reward: 263.0\n",
      "Episode: 1929, Step: 386338, Reward: 225.0\n",
      "Episode: 1930, Step: 386461, Reward: 123.0\n",
      "Episode: 1931, Step: 386961, Reward: 237.0\n",
      "Episode: 1932, Step: 387106, Reward: 145.0\n",
      "Episode: 1933, Step: 387402, Reward: 260.0\n",
      "Episode: 1934, Step: 387716, Reward: 269.0\n",
      "Episode: 1935, Step: 387988, Reward: 256.0\n",
      "Episode: 1936, Step: 388480, Reward: 255.0\n",
      "Episode: 1937, Step: 388592, Reward: 112.0\n",
      "Episode: 1938, Step: 388864, Reward: 254.0\n",
      "Episode: 1939, Step: 389011, Reward: 146.0\n",
      "Episode: 1940, Step: 389226, Reward: 211.0\n",
      "Episode: 1941, Step: 389723, Reward: 171.0\n",
      "Episode: 1942, Step: 390178, Reward: 256.0\n",
      "Episode: 1943, Step: 390399, Reward: 192.0\n",
      "Episode: 1944, Step: 390599, Reward: 198.0\n",
      "Episode: 1945, Step: 390751, Reward: 152.0\n",
      "Episode: 1946, Step: 391184, Reward: 259.0\n",
      "Episode: 1947, Step: 391416, Reward: 198.0\n",
      "Episode: 1948, Step: 391760, Reward: 265.0\n",
      "Episode: 1949, Step: 392249, Reward: 233.0\n",
      "Episode: 1950, Step: 392529, Reward: 263.0\n",
      "Episode: 1951, Step: 392732, Reward: 199.0\n",
      "Episode: 1952, Step: 392871, Reward: 135.0\n",
      "Episode: 1953, Step: 393298, Reward: 266.0\n",
      "Episode: 1954, Step: 393503, Reward: 199.0\n",
      "Episode: 1955, Step: 393635, Reward: 132.0\n",
      "Episode: 1956, Step: 393741, Reward: 106.0\n",
      "Episode: 1957, Step: 393881, Reward: 133.0\n",
      "Episode: 1958, Step: 394102, Reward: 220.0\n",
      "Episode: 1959, Step: 394157, Reward: 55.0\n",
      "Episode: 1960, Step: 394628, Reward: 229.0\n",
      "Episode: 1961, Step: 394917, Reward: 260.0\n",
      "Episode: 1962, Step: 395414, Reward: 249.0\n",
      "Episode: 1963, Step: 395654, Reward: 196.0\n",
      "Episode: 1964, Step: 395709, Reward: 55.0\n",
      "Episode: 1965, Step: 396013, Reward: 256.0\n",
      "Episode: 1966, Step: 396513, Reward: 238.0\n",
      "Episode: 1967, Step: 396783, Reward: 255.0\n",
      "Episode: 1968, Step: 397057, Reward: 260.0\n",
      "Episode: 1969, Step: 397253, Reward: 194.0\n",
      "Episode: 1970, Step: 397529, Reward: 263.0\n",
      "Episode: 1971, Step: 398013, Reward: 177.0\n",
      "Episode: 1972, Step: 398493, Reward: 235.0\n",
      "Episode: 1973, Step: 398775, Reward: 251.0\n",
      "Episode: 1974, Step: 399043, Reward: 259.0\n",
      "Episode: 1975, Step: 399314, Reward: 257.0\n",
      "Episode: 1976, Step: 399605, Reward: 262.0\n",
      "Episode: 1977, Step: 399717, Reward: 112.0\n",
      "Episode: 1978, Step: 400070, Reward: 262.0\n",
      "Episode: 1979, Step: 400351, Reward: 260.0\n",
      "Episode: 1980, Step: 400851, Reward: 247.0\n",
      "Episode: 1981, Step: 401206, Reward: 266.0\n",
      "Episode: 1982, Step: 401704, Reward: 254.0\n",
      "Episode: 1983, Step: 402069, Reward: 262.0\n",
      "Episode: 1984, Step: 402181, Reward: 112.0\n",
      "Episode: 1985, Step: 402388, Reward: 199.0\n",
      "Episode: 1986, Step: 402529, Reward: 137.0\n",
      "Episode: 1987, Step: 403029, Reward: 185.0\n",
      "Episode: 1988, Step: 403351, Reward: 261.0\n",
      "Episode: 1989, Step: 403691, Reward: 260.0\n",
      "Episode: 1990, Step: 404188, Reward: 257.0\n",
      "Episode: 1991, Step: 404458, Reward: 256.0\n",
      "Episode: 1992, Step: 404516, Reward: 56.0\n",
      "Episode: 1993, Step: 404996, Reward: 253.0\n",
      "Episode: 1994, Step: 405496, Reward: 175.0\n",
      "Episode: 1995, Step: 405967, Reward: 170.0\n",
      "Episode: 1996, Step: 406119, Reward: 150.0\n",
      "Episode: 1997, Step: 406325, Reward: 197.0\n",
      "Episode: 1998, Step: 406795, Reward: 267.0\n",
      "Episode: 1999, Step: 407146, Reward: 265.0\n",
      "Episode: 2000, Step: 407626, Reward: 252.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "step = 0\n",
    "generation = 0\n",
    "total_rewards = []\n",
    "for episode in range(n_episodes*3, n_episodes*4):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # ε-greedyで行動を選択\n",
    "        action = net.act(obs.float().to(device), epsilon_func(step))\n",
    "        # 環境中で実際に行動\n",
    "        next_obs, reward, done, info = env.step(make_action(action))\n",
    "        total_reward += reward\n",
    "\n",
    "        # リプレイバッファに経験を蓄積\n",
    "        replay_buffer.push([obs, action, reward, next_obs, done])\n",
    "        obs = next_obs\n",
    "\n",
    "        # ネットワークを更新            \n",
    "        if len(replay_buffer) > initial_buffer_size:\n",
    "            update(batch_size, beta_func(step))\n",
    "\n",
    "        # ターゲットネットワークを定期的に同期させる\n",
    "        if (step + 1) % target_update_interval == 0:\n",
    "            target_net.load_state_dict(net.state_dict())\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        if done or info[\"time\"] <= time_limit:\n",
    "            break\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    print(f\"Episode: {episode+1}, Step: {step}, Reward: {total_reward}\")\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        torch.save(net.state_dict(), os.path.join(model_path, f\"dqn_agent_gen_{generation}.pt\"))\n",
    "        generation += 1\n",
    "\n",
    "plt.plot(total_rewards, label=\"reward\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      "
     ]
    }
   ],
   "source": [
    "def valid():\n",
    "    \n",
    "    agent = CNNQNetwork(env.observation_space.shape, n_action=2).to(device)\n",
    "    state_dict = torch.load(\"models/dqn_agent.pt\")\n",
    "    agent.load_state_dict(state_dict)\n",
    "    \n",
    "    for episode in range(1):\n",
    "        obs_ = env.reset()\n",
    "\n",
    "        step_ = 0\n",
    "        done_ = False\n",
    "        while not done_:           \n",
    "            action_ = agent.act(obs_.float().to(device), epsilon=0.0)\n",
    "            next_obs_, reward_, done_, _ = env.step(make_action(action_))\n",
    "            obs_ = next_obs_\n",
    "            step_ += 1\n",
    "            \n",
    "            controller = \"→ \" if action_ == 0 else \"→A\"\n",
    "            text = f\"Step: {step_} Action: {controller}\"\n",
    "            print(f\"\\r{text}\", end=\"\")\n",
    "    \n",
    "        print(f\"\\r                      \", end=\"\")\n",
    "    \n",
    "valid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
